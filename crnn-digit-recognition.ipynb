{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nfrom torchvision.datasets import MNIST\nimport matplotlib.pyplot as plt\nfrom PIL import Image,ImageOps\nfrom torchvision import transforms\nimport os\nfrom torch.utils.data import Dataset,DataLoader,ConcatDataset,SubsetRandomSampler\nimport pandas as pd\nimport glob\nimport uuid\nimport random\nimport cv2 \nimport albumentations as A\nfrom albumentations.augmentations.geometric.rotate import Rotate\nfrom albumentations.augmentations.geometric.transforms import ElasticTransform\nfrom itertools import groupby\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.nn.init as init\nfrom torchmetrics import Recall, Precision\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-30T05:08:13.493176Z","iopub.execute_input":"2022-05-30T05:08:13.493865Z","iopub.status.idle":"2022-05-30T05:08:13.503078Z","shell.execute_reply.started":"2022-05-30T05:08:13.493826Z","shell.execute_reply":"2022-05-30T05:08:13.502109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((224,224))])\naug_transform = A.Compose([\n   ElasticTransform(p=1.0,border_mode=cv2.BORDER_REPLICATE,approximate=True,same_dxdy=True),\n   Rotate(limit=20,p=0.6)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-30T05:08:14.033101Z","iopub.execute_input":"2022-05-30T05:08:14.033492Z","iopub.status.idle":"2022-05-30T05:08:14.041691Z","shell.execute_reply.started":"2022-05-30T05:08:14.033458Z","shell.execute_reply":"2022-05-30T05:08:14.040626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/csv-file/filtered.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T05:08:14.547338Z","iopub.execute_input":"2022-05-30T05:08:14.547737Z","iopub.status.idle":"2022-05-30T05:08:14.565569Z","shell.execute_reply.started":"2022-05-30T05:08:14.547703Z","shell.execute_reply":"2022-05-30T05:08:14.564695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open(\"../input/english-handwritten-characters-dataset/Img/img002-032.png\")\nimg2 = Image.open(\"../input/english-handwritten-characters-dataset/Img/img003-010.png\")\n\nimg=transform(img)\nimg2=transform(img2)\n\nimg = np.asarray(img)\nimg2=np.asarray(img2)\na = np.concatenate([img[:,:170],img2[:,45:]],axis=1)\na=Image.fromarray(a)\na=transform(a)\na=np.asarray(a)\naug = aug_transform(image=a)\naug_image = aug[\"image\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-30T05:08:21.430475Z","iopub.execute_input":"2022-05-30T05:08:21.430881Z","iopub.status.idle":"2022-05-30T05:08:21.539194Z","shell.execute_reply.started":"2022-05-30T05:08:21.430845Z","shell.execute_reply":"2022-05-30T05:08:21.538291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(aug_image)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T05:08:21.862955Z","iopub.execute_input":"2022-05-30T05:08:21.86332Z","iopub.status.idle":"2022-05-30T05:08:22.085186Z","shell.execute_reply.started":"2022-05-30T05:08:21.863288Z","shell.execute_reply":"2022-05-30T05:08:22.084371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.281953Z","iopub.execute_input":"2022-05-29T12:31:00.282358Z","iopub.status.idle":"2022-05-29T12:31:00.296934Z","shell.execute_reply.started":"2022-05-29T12:31:00.282317Z","shell.execute_reply":"2022-05-29T12:31:00.296204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.size","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.298288Z","iopub.execute_input":"2022-05-29T12:31:00.298722Z","iopub.status.idle":"2022-05-29T12:31:00.30524Z","shell.execute_reply.started":"2022-05-29T12:31:00.298675Z","shell.execute_reply":"2022-05-29T12:31:00.304461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = dict()\n\n\nd[\"0\"]= df[df[\"label\"]==0].iloc[:,1].tolist()\nd[\"1\"]=df[df[\"label\"]==1].iloc[:,1].tolist()\nd[\"2\"]=df[df[\"label\"]==2].iloc[:,1].tolist()\nd[\"3\"]=df[df[\"label\"]==3].iloc[:,1].tolist()\nd[\"4\"]=df[df[\"label\"]==4].iloc[:,1].tolist()\nd[\"5\"]=df[df[\"label\"]==5].iloc[:,1].tolist()\nd[\"6\"]=df[df[\"label\"]==6].iloc[:,1].tolist()\nd[\"7\"]=df[df[\"label\"]==7].iloc[:,1].tolist()\nd[\"8\"]=df[df[\"label\"]==8].iloc[:,1].tolist()\nd[\"9\"]=df[df[\"label\"]==9].iloc[:,1].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.3065Z","iopub.execute_input":"2022-05-29T12:31:00.307568Z","iopub.status.idle":"2022-05-29T12:31:00.327295Z","shell.execute_reply.started":"2022-05-29T12:31:00.307512Z","shell.execute_reply":"2022-05-29T12:31:00.326535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path=\"../input/english-handwritten-characters-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.328527Z","iopub.execute_input":"2022-05-29T12:31:00.329034Z","iopub.status.idle":"2022-05-29T12:31:00.336239Z","shell.execute_reply.started":"2022-05-29T12:31:00.328975Z","shell.execute_reply":"2022-05-29T12:31:00.335367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def number_list(root,df,transform):\n    num_list = []\n    aug_num_list = []\n    for i in df.iterrows():\n        image = Image.open(root+i[1][1])\n        label = i[1][2]\n        image = transform(image)\n        image_copy = np.asarray(image)\n        \n        for j in range(5):\n            aug = aug_transform(image=image_copy)\n            aug_image = aug[\"image\"]\n            aug_image = Image.fromarray(aug_image)\n            aug_num_list.append((aug_image,label))\n        \n        num_list.append((image,label))\n\n    return num_list,aug_num_list\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.339737Z","iopub.execute_input":"2022-05-29T12:31:00.340265Z","iopub.status.idle":"2022-05-29T12:31:00.347599Z","shell.execute_reply.started":"2022-05-29T12:31:00.340229Z","shell.execute_reply":"2022-05-29T12:31:00.346728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_list_1,aug_num_1=number_list(root_path,df,transform)\nprint(len(num_list_1),len(aug_num_1))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:00.348814Z","iopub.execute_input":"2022-05-29T12:31:00.349313Z","iopub.status.idle":"2022-05-29T12:31:15.256995Z","shell.execute_reply.started":"2022-05-29T12:31:00.349274Z","shell.execute_reply":"2022-05-29T12:31:15.256176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_numbers(root,d,transform):\n    num_list=[]\n    aug_num_list = []\n    for i in range(10,101):\n        \n        val=str(i)\n        l1=d[val[0]]\n        l2=d[val[1]]\n        for j in range(55):\n            \n            num1 = np.random.choice(l1)\n            num2 = np.random.choice(l2)\n            \n            img = Image.open(root+num1)\n            img2 = Image.open(root+num2)\n            \n            img=transform(img)\n            img2=transform(img2)\n\n            img = np.asarray(img)\n            img2=np.asarray(img2)\n            \n            if i==100:\n                a = np.concatenate([img[:,:170],img2[:,45:170],img2[:,45:]],axis=1)\n            else:    \n                a = np.concatenate([img[:,:170],img2[:,45:]],axis=1)\n                \n            a=Image.fromarray(a)\n            a=transform(a)\n            \n            image_copy = np.asarray(a)\n        \n            for j in range(5):\n                aug = aug_transform(image=image_copy)\n                aug_image = aug[\"image\"]\n                aug_image = Image.fromarray(aug_image)\n                aug_num_list.append((aug_image,i))\n\n\n            \n            num_list.append((a,i))\n            \n            \n    return num_list,aug_num_list\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:15.258098Z","iopub.execute_input":"2022-05-29T12:31:15.258954Z","iopub.status.idle":"2022-05-29T12:31:15.270929Z","shell.execute_reply.started":"2022-05-29T12:31:15.258915Z","shell.execute_reply":"2022-05-29T12:31:15.270018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_list_2,aug_num_2 = create_numbers(root_path,d,transform)\nprint(len(num_list_2),len(aug_num_2))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:31:15.273794Z","iopub.execute_input":"2022-05-29T12:31:15.274052Z","iopub.status.idle":"2022-05-29T12:34:35.895938Z","shell.execute_reply.started":"2022-05-29T12:31:15.274029Z","shell.execute_reply":"2022-05-29T12:34:35.895118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_list = num_list_1+ num_list_2\naug_list = aug_num_1 + aug_num_2\n\nprint(len(num_list),len(aug_list))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.897269Z","iopub.execute_input":"2022-05-29T12:34:35.897797Z","iopub.status.idle":"2022-05-29T12:34:35.904028Z","shell.execute_reply.started":"2022-05-29T12:34:35.897758Z","shell.execute_reply":"2022-05-29T12:34:35.903264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_test_list = [num_list.pop(random.randrange(len(num_list))) for _ in range(3333)]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.905231Z","iopub.execute_input":"2022-05-29T12:34:35.905753Z","iopub.status.idle":"2022-05-29T12:34:35.919023Z","shell.execute_reply.started":"2022-05-29T12:34:35.905716Z","shell.execute_reply":"2022-05-29T12:34:35.918193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_list = num_list+aug_list","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.920394Z","iopub.execute_input":"2022-05-29T12:34:35.921115Z","iopub.status.idle":"2022-05-29T12:34:35.927325Z","shell.execute_reply.started":"2022-05-29T12:34:35.921078Z","shell.execute_reply":"2022-05-29T12:34:35.926594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Numbers(Dataset):\n    def __init__(self,image_list,max_length,transform):\n        self.image_list=image_list\n        self.transform=transform\n        self.max_length = max_length\n    def __len__(self):\n        return len(self.image_list)\n    \n    def __getitem__(self,index):\n        image = self.image_list[index][0]\n        image=ImageOps.grayscale(image)\n        image = np.asarray(image)\n        \n        blur = cv2.GaussianBlur(image,(5,5),0)\n    \n        ret3,th3 = cv2.threshold(blur,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n        image = Image.fromarray(th3)\n        \n        label = self.image_list[index][1]\n        label_len = len(str(label))\n        mod_label=[]\n        string_label = str(label)\n        \n        for s in range(self.max_length):\n            if s>len(string_label)-1:\n                mod_label.append(-1)\n                continue\n            mod_label.append(int(string_label[s]))\n        \n        y_label=torch.tensor(mod_label)\n            \n        if self.transform:\n            image=self.transform(image)\n\n            \n        return (image,y_label,label_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.929414Z","iopub.execute_input":"2022-05-29T12:34:35.930745Z","iopub.status.idle":"2022-05-29T12:34:35.942014Z","shell.execute_reply.started":"2022-05-29T12:34:35.930718Z","shell.execute_reply":"2022-05-29T12:34:35.941065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform2 = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = Numbers(num_list,3,transform2)\nval_test_dataset = Numbers(val_test_list,3,transform2)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.943416Z","iopub.execute_input":"2022-05-29T12:34:35.944044Z","iopub.status.idle":"2022-05-29T12:34:35.951226Z","shell.execute_reply.started":"2022-05-29T12:34:35.944004Z","shell.execute_reply":"2022-05-29T12:34:35.950315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set,test_set=torch.utils.data.random_split(val_test_dataset,[2222,1111])\n\ntrain_loader=DataLoader(dataset=train_dataset,batch_size=64,shuffle=True)\ntest_loader=DataLoader(dataset=test_set,batch_size=64,shuffle=True)\nval_loader=DataLoader(dataset=val_set,batch_size=64,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.953396Z","iopub.execute_input":"2022-05-29T12:34:35.954089Z","iopub.status.idle":"2022-05-29T12:34:35.962136Z","shell.execute_reply.started":"2022-05-29T12:34:35.95405Z","shell.execute_reply":"2022-05-29T12:34:35.961224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VGG_types = {\n    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n    \"VGG16\": [\n        64,\n        64,\n        \"M\",\n        128,\n        128,\n        \"M\",\n        256,\n        256,\n        256,\n        \"M\",\n        512,\n        512,\n        512,\n        \"M\",\n        512,\n        512,\n        512,\n        \"M\",\n    ],\n    \"VGG19\": [\n        64,\n        64,\n        \"M\",\n        128,\n        128,\n        \"M\",\n        256,\n        256,\n        256,\n        256,\n        \"M\",\n        512,\n        512,\n        512,\n        512,\n        \"M\",\n        512,\n        512,\n        512,\n        512,\n        \"M\",\n    ],\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.963754Z","iopub.execute_input":"2022-05-29T12:34:35.96413Z","iopub.status.idle":"2022-05-29T12:34:35.972318Z","shell.execute_reply.started":"2022-05-29T12:34:35.964083Z","shell.execute_reply":"2022-05-29T12:34:35.971356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.Size([32, 512, 7, 7])\nclass CRNN(nn.Module):\n\n    def __init__(self,device,cnn_type):\n        super(CRNN, self).__init__()\n        self.in_channels=1\n        self.device=device\n        self.num_classes = 10 + 1\n        self.image_H = 28\n\n        self.vgg = self.create_conv_layers(cnn_type)\n#         self.get_dims = self.vgg(torch.randn(1,1,224,224))\n        self.postconv_height = 7\n        self.postconv_width = 7\n        self.gru_input_size = self.postconv_height * 64\n        self.gru_hidden_size = 128 \n        self.gru_num_layers = 2\n        self.gru_h = None\n        self.gru_cell = None\n\n        self.gru = nn.GRU(self.gru_input_size, self.gru_hidden_size, self.gru_num_layers, batch_first = True, bidirectional = True)\n\n        self.fc = nn.Linear(self.gru_hidden_size * 2, self.num_classes)\n\n\n    def create_conv_layers(self,architecture):\n        layers=[]\n        in_channels=self.in_channels\n        \n        for x in architecture:\n            \n            if type(x)==int:\n                out_channels=x\n                layers+=[\n                    nn.Conv2d\n                    (\n                        in_channels,out_channels,\n                        kernel_size=(3, 3),\n                        stride=(1, 1),\n                        padding=(1, 1),\n                    ),\n                    nn.InstanceNorm2d(x),\n                    nn.LeakyReLU(0.01),\n                ]\n                in_channels=x\n                \n            elif x==\"M\":\n                layers+=[nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n                \n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        batch_size = x.shape[0]\n        out = self.vgg(x)\n        \n        out = out.permute(0, 3, 2, 1) \n        out = out.reshape(batch_size, -1, self.gru_input_size)\n\n        out, gru_h = self.gru(out, self.gru_h)\n       \n        self.gru_h = gru_h.detach()\n        out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n\n        return out\n\n    def reset_hidden(self,batch_size):\n        h = torch.zeros(self.gru_num_layers * 2,batch_size , self.gru_hidden_size,device=self.device)\n        self.gru_h = Variable(h)\n\ncrnn = CRNN(device,VGG_types[\"VGG19\"]).to(device)\ncriterion = nn.CTCLoss(blank=10, reduction='mean', zero_infinity=True)\noptimizer = torch.optim.Adam(crnn.parameters(), lr=3e-4) \nPATH = \"best_model_vgg.pth\"","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:35.973964Z","iopub.execute_input":"2022-05-29T12:34:35.975051Z","iopub.status.idle":"2022-05-29T12:34:41.260185Z","shell.execute_reply.started":"2022-05-29T12:34:35.974842Z","shell.execute_reply":"2022-05-29T12:34:41.259389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = torch.randn(1,1,224,224)\n# out = crnn(a)\n# out.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:41.261644Z","iopub.execute_input":"2022-05-29T12:34:41.261974Z","iopub.status.idle":"2022-05-29T12:34:41.266185Z","shell.execute_reply.started":"2022-05-29T12:34:41.261939Z","shell.execute_reply":"2022-05-29T12:34:41.265354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nbest_val = -1\nfor e in range(20):\n    \n    BLANK_LABEL=10\n\n    num_batches =0\n    total_loss = 0\n    \n    crnn.train()\n    for (inputs,labels,label_size) in train_loader:\n        \n        correct = 0\n        total = 0\n        \n        inputs,labels = inputs.to(device),labels.to(device)\n        batch_size = len(inputs)\n        crnn.reset_hidden(batch_size)\n\n        optimizer.zero_grad()  \n        \n        y_pred = crnn(inputs)\n        y_pred = y_pred.permute(1, 0, 2)\n\n        input_lengths = torch.IntTensor(batch_size).fill_(crnn.postconv_width)\n        target_lengths = torch.IntTensor([t for t in label_size])\n\n        loss = criterion(y_pred, labels, input_lengths, target_lengths)\n        \n        total_loss+=loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n        \n        num_batches += 1\n        \n\n    \n    crnn.eval()\n    with torch.no_grad():\n        val_correct = 0\n        val_total = 0\n        val_batches = 0\n        running_precision = 0\n        running_recall = 0\n        batch_precision = 0\n        batch_recall = 0\n        prec = Precision()\n        rec = Recall()\n        for (inputs,labels,label_size) in val_loader:\n            \n            inputs,labels = inputs.to(device),labels.to(device)\n            batch_size = len(inputs)\n            crnn.reset_hidden(batch_size)\n            \n            y_pred = crnn(inputs)\n            y_pred = y_pred.permute(1, 0, 2)\n            \n            _, max_index = torch.max(y_pred, dim=2)\n            \n            for i in range(batch_size):\n                raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n\n                prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != BLANK_LABEL])\n                ground_truth = labels[i].detach().cpu()\n                ground_truth = ground_truth[ground_truth!=-1]\n\n                if len(prediction) == len(ground_truth) and torch.all(prediction.eq(ground_truth)):\n                    val_correct += 1\n                val_total += 1\n                \n                preds = \"\"\n                g_truth = \"\"\n                for k in prediction:\n                    preds+=str(k.item())\n                preds = int(preds)\n                preds = torch.tensor([preds])\n                \n                for k in ground_truth:\n                    g_truth+=str(k.item())\n                    \n                g_truth = int(g_truth)\n                g_truth = torch.tensor([g_truth])\n    \n                running_precision+=prec(preds,g_truth).item()\n                running_recall+=rec(preds,g_truth).item()\n            \n            running_precision = running_precision/batch_size\n            running_recall = running_recall/batch_size\n            \n            batch_precision+=running_precision\n            batch_recall+=running_recall\n            \n            val_batches+=1\n                \n        if val_correct>best_val:\n            best_val = val_correct\n            torch.save(crnn.state_dict(), PATH)\n            print(\"Best val correct:\",best_val)\n            print(\"SAVING MODEL\")\n            \n    print(\"Epoch:{e} val_total:{total} val_correct:{correct}\".format(e=e,total=val_total,correct=val_correct))\n    print(\"Epoch:{e} precision_val:{prec_val} recall_val:{rec_val}\".format(e=e,prec_val=batch_precision/val_batches,rec_val=batch_recall/val_batches))\n    print(\"Epoch:{e} train_loss:{Loss}\".format(e=e,Loss=total_loss / num_batches))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:34:41.27993Z","iopub.execute_input":"2022-05-29T12:34:41.280572Z","iopub.status.idle":"2022-05-29T12:38:36.333539Z","shell.execute_reply.started":"2022-05-29T12:34:41.280517Z","shell.execute_reply":"2022-05-29T12:38:36.33234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Testing**","metadata":{}},{"cell_type":"code","source":"crnn.eval()\nwith torch.no_grad():\n    val_correct = 0\n    val_total = 0\n    val_batches = 0\n    running_precision = 0\n    running_recall = 0\n    batch_precision = 0\n    batch_recall = 0\n    prec = Precision()\n    rec = Recall()\n    for (inputs,labels,label_size) in test_loader:\n\n        inputs,labels = inputs.to(device),labels.to(device)\n        batch_size = len(inputs)\n        crnn.reset_hidden(batch_size)\n\n        y_pred = crnn(inputs)\n        y_pred = y_pred.permute(1, 0, 2)\n\n        _, max_index = torch.max(y_pred, dim=2)\n\n        for i in range(batch_size):\n            raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n\n            prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != BLANK_LABEL])\n            ground_truth = labels[i].detach().cpu()\n            ground_truth = ground_truth[ground_truth!=-1]\n\n            if len(prediction) == len(ground_truth) and torch.all(prediction.eq(ground_truth)):\n                val_correct += 1\n            val_total += 1\n\n            preds = \"\"\n            g_truth = \"\"\n            for k in prediction:\n                preds+=str(k.item())\n            preds = int(preds)\n            preds = torch.tensor([preds])\n\n            for k in ground_truth:\n                g_truth+=str(k.item())\n\n            g_truth = int(g_truth)\n            g_truth = torch.tensor([g_truth])\n\n            running_precision+=prec(preds,g_truth).item()\n            running_recall+=rec(preds,g_truth).item()\n\n        running_precision = running_precision/batch_size\n        running_recall = running_recall/batch_size\n\n        batch_precision+=running_precision\n        batch_recall+=running_recall\n\n        val_batches+=1\n        \n\n    print(\"Epoch:{e} val_total:{total} val_correct:{correct}\".format(e=e,total=val_total,correct=val_correct))\n    print(\"Epoch:{e} precision_val:{prec_val} recall_val:{rec_val}\".format(e=e,prec_val=batch_precision/val_batches,rec_val=batch_recall/val_batches))","metadata":{},"execution_count":null,"outputs":[]}]}