{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport segmentation_models_pytorch as smp\nfrom torch.utils.data import Dataset,DataLoader,ConcatDataset,SubsetRandomSampler\nimport numpy as np \nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\nfrom torchvision import transforms\nimport pandas as pd\nfrom torchvision.models.segmentation import fcn_resnet101\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T17:00:54.624913Z","iopub.execute_input":"2022-05-12T17:00:54.625205Z","iopub.status.idle":"2022-05-12T17:00:58.133356Z","shell.execute_reply.started":"2022-05-12T17:00:54.625175Z","shell.execute_reply":"2022-05-12T17:00:58.132527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/camvid/CamVid/class_dict.csv\")\nlabel_dict = dict()\ndf\nfor x,rows in enumerate(df.iterrows()):\n    rgb = [rows[1]['r'],rows[1]['g'],rows[1]['b']]\n    label_dict[x] = rgb","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:26.525287Z","iopub.execute_input":"2022-05-12T17:01:26.525614Z","iopub.status.idle":"2022-05-12T17:01:26.549909Z","shell.execute_reply.started":"2022-05-12T17:01:26.525582Z","shell.execute_reply":"2022-05-12T17:01:26.549198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:26.817221Z","iopub.execute_input":"2022-05-12T17:01:26.817808Z","iopub.status.idle":"2022-05-12T17:01:26.825942Z","shell.execute_reply.started":"2022-05-12T17:01:26.81777Z","shell.execute_reply":"2022-05-12T17:01:26.825156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"../input/camvid/CamVid/train/0001TP_009240.png\")\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nmask = cv2.imread(\"../input/camvid/CamVid/train_labels/0001TP_009240_L.png\")\nmask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\nprint(img .shape)\nprint(mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:27.097584Z","iopub.execute_input":"2022-05-12T17:01:27.098445Z","iopub.status.idle":"2022-05-12T17:01:27.185486Z","shell.execute_reply.started":"2022-05-12T17:01:27.0984Z","shell.execute_reply":"2022-05-12T17:01:27.184711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:27.37601Z","iopub.execute_input":"2022-05-12T17:01:27.376267Z","iopub.status.idle":"2022-05-12T17:01:27.392957Z","shell.execute_reply.started":"2022-05-12T17:01:27.376238Z","shell.execute_reply":"2022-05-12T17:01:27.392208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:27.631287Z","iopub.execute_input":"2022-05-12T17:01:27.631565Z","iopub.status.idle":"2022-05-12T17:01:27.945954Z","shell.execute_reply.started":"2022-05-12T17:01:27.631537Z","shell.execute_reply":"2022-05-12T17:01:27.945314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_mask(mask,label_dict):\n    segmentation_map_list = []\n    for x,color in enumerate(label_dict.values()):\n        segmentation_map = (mask==color).all(axis=-1)\n        segmentation_map=(segmentation_map*1)\n        segmentation_map*=x\n        segmentation_map_list.append(segmentation_map)\n        \n    return np.amax(np.stack(segmentation_map_list,axis=-1),axis=-1)\n\ndef convert_n_channels_2_rgb(image,label_dict):\n    image = np.amax(image,axis=-1)\n    r = np.zeros_like(image).astype(np.uint8)\n    g = np.zeros_like(image).astype(np.uint8)\n    b = np.zeros_like(image).astype(np.uint8)\n    \n    for l in label_dict.keys():\n        idx = image==l\n        r[idx] = label_dict[l][0]\n        g[idx] = label_dict[l][1]\n        b[idx] = label_dict[l][2]\n    return np.stack([r,g,b],axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:27.947493Z","iopub.execute_input":"2022-05-12T17:01:27.947897Z","iopub.status.idle":"2022-05-12T17:01:27.956963Z","shell.execute_reply.started":"2022-05-12T17:01:27.947859Z","shell.execute_reply":"2022-05-12T17:01:27.956179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CamVidDataset(Dataset):\n    def __init__(self,label_dict,IMAGE_PATH,MASK_PATH,transforms,mask_transforms):\n        self.image_list = glob.glob(IMAGE_PATH)\n        self.label_list = glob.glob(MASK_PATH)\n        self.label_dict = label_dict\n        self.transform = transforms\n        self.mask_transforms = mask_transforms\n        \n        self.image_list.sort()\n        self.label_list.sort()\n        \n    def __len__(self):\n        return len(self.image_list)\n    \n    def __getitem__(self,idx):\n        img = cv2.imread(self.image_list[idx])\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.label_list[idx])\n        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n\n        if self.transform:\n            img = self.transform(img)\n        \n        if self.mask_transforms:\n            mask = self.mask_transforms(mask)\n            \n        mask = np.array(mask)\n        mask = adjust_mask(mask,self.label_dict)\n        mask = torch.tensor(mask)\n        mask = torch.squeeze(mask,dim=0)\n        return img,mask\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:01:28.764209Z","iopub.execute_input":"2022-05-12T17:01:28.76477Z","iopub.status.idle":"2022-05-12T17:01:28.773377Z","shell.execute_reply.started":"2022-05-12T17:01:28.764732Z","shell.execute_reply":"2022-05-12T17:01:28.772668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    ])\n\nmask_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224))\n    ])\n\nIMAGE_PATH = \"../input/camvid/CamVid/train/*.png\"\nMASK_PATH = \"../input/camvid/CamVid/train_labels/*.png\"\n\nVAL_PATH = \"../input/camvid/CamVid/val/*.png\"\nVAL_MASK = \"../input/camvid/CamVid/val_labels/*.png\"\n\ntrain_dataset = CamVidDataset(label_dict,IMAGE_PATH,MASK_PATH,transform,mask_transforms)\n# trainloader = DataLoader(train_dataset,batch_size = 32,shuffle = True)\n\nval_dataset = CamVidDataset(label_dict,VAL_PATH,VAL_MASK,transform,mask_transforms)\n# val_loader = DataLoader(val_dataset,batch_size = 32,shuffle = True)\ndataset = ConcatDataset([train_dataset,val_dataset])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:21:59.90273Z","iopub.execute_input":"2022-05-12T14:21:59.903521Z","iopub.status.idle":"2022-05-12T14:22:00.311253Z","shell.execute_reply.started":"2022-05-12T14:21:59.903461Z","shell.execute_reply":"2022-05-12T14:22:00.310498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:02:51.124698Z","iopub.execute_input":"2022-05-08T14:02:51.125257Z","iopub.status.idle":"2022-05-08T14:02:51.13155Z","shell.execute_reply.started":"2022-05-08T14:02:51.125217Z","shell.execute_reply":"2022-05-08T14:02:51.130693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = fcn_resnet101(num_classes = 32, pretrained_backbone = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:01:05.411302Z","iopub.execute_input":"2022-05-07T13:01:05.411526Z","iopub.status.idle":"2022-05-07T13:01:07.647591Z","shell.execute_reply.started":"2022-05-07T13:01:05.4115Z","shell.execute_reply":"2022-05-07T13:01:07.646799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nprint(\"model initialized\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:01:07.651116Z","iopub.execute_input":"2022-05-07T13:01:07.651321Z","iopub.status.idle":"2022-05-07T13:01:10.322547Z","shell.execute_reply.started":"2022-05-07T13:01:07.651297Z","shell.execute_reply":"2022-05-07T13:01:10.321094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\nkf = KFold(n_splits=5)\nscheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=0.1,step_size_up=5,mode=\"triangular2\",cycle_momentum=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:03:24.466713Z","iopub.execute_input":"2022-05-08T14:03:24.467514Z","iopub.status.idle":"2022-05-08T14:03:24.474477Z","shell.execute_reply.started":"2022-05-08T14:03:24.46747Z","shell.execute_reply":"2022-05-08T14:03:24.473256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weight_reset(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        m.reset_parameters()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:01:10.333364Z","iopub.execute_input":"2022-05-07T13:01:10.334182Z","iopub.status.idle":"2022-05-07T13:01:10.340437Z","shell.execute_reply.started":"2022-05-07T13:01:10.334143Z","shell.execute_reply":"2022-05-07T13:01:10.339636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()\nfold=0\nfor train_index, test_index in kf.split(dataset):\n    sampler_train = SubsetRandomSampler(train_index)\n    sampler_val = SubsetRandomSampler(test_index)\n    \n    trainloader = DataLoader(dataset = dataset,batch_size = 32,sampler = sampler_train)\n    val_loader = DataLoader(dataset = dataset,batch_size = 32,sampler = sampler_val)\n   \n    model.apply(weight_reset)\n    \n    for e in range(10):\n        running_loss_train = 0\n        running_loss_val = 0\n        model.train()\n        for x,(inputs,labels) in enumerate(trainloader):\n            inputs,labels = inputs.to(device),labels.to(device) \n            outputs = model(inputs)[\"out\"]\n            loss_train = criterion(outputs,labels)\n            \n            running_loss_train+=(loss_train.item()*inputs.size(0))\n            \n            optimizer.zero_grad()\n            loss_train.backward()\n\n            optimizer.step()\n\n\n        model.eval()\n        with torch.no_grad():\n            for x,(inputs,labels) in enumerate(val_loader):\n                inputs,labels = inputs.to(device),labels.to(device)\n                outputs = model(inputs)[\"out\"]\n                loss_val = criterion(outputs,labels)\n                running_loss_val+=(loss_val.item()*inputs.size(0))\n        \n        print(\"Fold:{fold} Epoch:{epoch} Train loss:{train_loss} Val loss:{val_loss}\".format(fold=fold,epoch=e,train_loss=(running_loss_train/len(train_index)),val_loss=(running_loss_val/len(test_index))))\n    \n   \n    PATH = str(fold)+\".pth\"\n    torch.save(model.state_dict(), PATH)\n    \n    \n#     scheduler.step()\n    \n    \n        \n    fold+=1","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:06:29.947787Z","iopub.execute_input":"2022-05-07T13:06:29.948064Z","iopub.status.idle":"2022-05-07T13:06:53.179305Z","shell.execute_reply.started":"2022-05-07T13:06:29.948035Z","shell.execute_reply":"2022-05-07T13:06:53.178024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Train k models on the entire dataset**","metadata":{}},{"cell_type":"code","source":"def train_model(model,model_name,trainloader,epoch,device,dataset_size,PATH):\n    criterion=nn.CrossEntropyLoss()\n    optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n    model.train()\n    for e in range(epoch):\n        running_loss_train = 0\n        running_loss_val = 0\n        train_loss = None\n        for x,(inputs,labels) in enumerate(trainloader):\n            inputs,labels = inputs.to(device),labels.to(device) \n            outputs = model(inputs)[\"out\"]\n            loss_train = criterion(outputs,labels)\n            \n            running_loss_train+=(loss_train.item()*inputs.size(0))\n            \n            optimizer.zero_grad()\n            loss_train.backward()\n            optimizer.step()\n            \n        train_loss = running_loss_train/dataset_size\n        \n        print(\"Epoch:{epoch} Train loss:{train_loss} model_name:{model_name}\".format(epoch = e,train_loss = train_loss,model_name=model_name))\n    \n    torch.save(model.state_dict(), PATH)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:07.232839Z","iopub.execute_input":"2022-05-08T14:04:07.233111Z","iopub.status.idle":"2022-05-08T14:04:07.240152Z","shell.execute_reply.started":"2022-05-08T14:04:07.233083Z","shell.execute_reply":"2022-05-08T14:04:07.239466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0 = fcn_resnet101(num_classes = 32, pretrained_backbone = True).to(device)\nmodel_1 = fcn_resnet101(num_classes = 32, pretrained_backbone = True).to(device)\nmodel_2 = fcn_resnet101(num_classes = 32, pretrained_backbone = True).to(device)\nmodel_3 = fcn_resnet101(num_classes = 32, pretrained_backbone = True).to(device)\nmodel_4 = fcn_resnet101(num_classes = 32, pretrained_backbone = True).to(device)\n\nmodel_list = [model_0,model_1,model_2,model_3,model_4]\n\ndataloader = DataLoader(dataset = dataset, batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:39.517761Z","iopub.execute_input":"2022-05-08T14:04:39.518411Z","iopub.status.idle":"2022-05-08T14:04:44.354067Z","shell.execute_reply.started":"2022-05-08T14:04:39.518373Z","shell.execute_reply":"2022-05-08T14:04:44.3533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,m in enumerate(model_list):\n    model_name = \"model\"+str(i)\n    PATH = model_name+\".pth\"\n    train_model(m,model_name,dataloader,10,device,len(dataset),PATH)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:49.912958Z","iopub.execute_input":"2022-05-08T14:04:49.913654Z","iopub.status.idle":"2022-05-08T14:06:03.523021Z","shell.execute_reply.started":"2022-05-08T14:04:49.913611Z","shell.execute_reply":"2022-05-08T14:06:03.521702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Evaluating all 5 models on test dataset**","metadata":{}},{"cell_type":"code","source":"def test_model(model,model_name,testloader,device,dataset_size):\n    criterion=nn.CrossEntropyLoss()\n    model.eval()\n    test_loss = None\n    running_loss_test = 0\n    with torch.no_grad():\n        for x,(inputs,labels) in enumerate(testloader):\n            inputs,labels = inputs.to(device),labels.to(device) \n            outputs = model(inputs)[\"out\"]\n            loss_test = criterion(outputs,labels)\n\n            running_loss_test+=(loss_test.item()*inputs.size(0))\n\n    test_loss = running_loss_test/dataset_size\n\n    print(\"Test loss:{test_loss} model_name:{model_name}\".format(test_loss = test_loss,model_name=model_name))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T15:49:14.922708Z","iopub.execute_input":"2022-05-08T15:49:14.922988Z","iopub.status.idle":"2022-05-08T15:49:14.930762Z","shell.execute_reply.started":"2022-05-08T15:49:14.922957Z","shell.execute_reply":"2022-05-08T15:49:14.929778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0 = fcn_resnet101(num_classes = 32).to(device)\nmodel_1 = fcn_resnet101(num_classes = 32).to(device)\nmodel_2 = fcn_resnet101(num_classes = 32).to(device)\nmodel_3 = fcn_resnet101(num_classes = 32).to(device)\nmodel_4 = fcn_resnet101(num_classes = 32).to(device)\n\n\n\nmodel_list = [model_0,model_1,model_2,model_3,model_4]\nMODEL_PATH = \"../input/notebook78f5a049d1/\"\n\nTEST_IMAGE_PATH = \"../input/camvid/CamVid/test/*.png\"\nTEST_MASK_PATH = \"../input/camvid/CamVid/test_labels/*.png\"\n\ntransform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    ])\n\nmask_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224))\n    ])\n\ntest_dataset = CamVidDataset(label_dict,TEST_IMAGE_PATH,TEST_MASK_PATH,transform,mask_transforms)\ntest_dataloader = DataLoader(dataset = test_dataset , batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T15:49:16.150525Z","iopub.execute_input":"2022-05-08T15:49:16.151151Z","iopub.status.idle":"2022-05-08T15:49:21.822767Z","shell.execute_reply.started":"2022-05-08T15:49:16.15111Z","shell.execute_reply":"2022-05-08T15:49:21.821978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,m in enumerate(model_list):\n    model_name = \"model\"+str(i)\n    m.load_state_dict(torch.load(MODEL_PATH+model_name+\".pth\"))\n    test_model(m,model_name,test_dataloader,device,len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T15:49:21.827091Z","iopub.execute_input":"2022-05-08T15:49:21.827312Z","iopub.status.idle":"2022-05-08T15:49:36.895148Z","shell.execute_reply.started":"2022-05-08T15:49:21.827284Z","shell.execute_reply":"2022-05-08T15:49:36.893947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ** Evaluate ensemble of 5 models on test dataset **","metadata":{}},{"cell_type":"code","source":"model_0 = fcn_resnet101(num_classes = 32).to(device)\nmodel_1 = fcn_resnet101(num_classes = 32).to(device)\nmodel_2 = fcn_resnet101(num_classes = 32).to(device)\nmodel_3 = fcn_resnet101(num_classes = 32).to(device)\nmodel_4 = fcn_resnet101(num_classes = 32).to(device)\n\n\n\nmodel_list = [model_0,model_1,model_2,model_3,model_4]\nMODEL_PATH = \"../input/models/\"\n\nmodel_0.load_state_dict(torch.load(MODEL_PATH+\"model0.pth\"))\nmodel_1.load_state_dict(torch.load(MODEL_PATH+\"model1.pth\"))\nmodel_2.load_state_dict(torch.load(MODEL_PATH+\"model2.pth\"))\nmodel_3.load_state_dict(torch.load(MODEL_PATH+\"model3.pth\"))\nmodel_4.load_state_dict(torch.load(MODEL_PATH+\"model4.pth\"))\n\nTEST_IMAGE_PATH = \"../input/camvid/CamVid/test/*.png\"\nTEST_MASK_PATH = \"../input/camvid/CamVid/test_labels/*.png\"\n\ntransform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    ])\n\nmask_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224,224))\n    ])\n\ntest_dataset = CamVidDataset(label_dict,TEST_IMAGE_PATH,TEST_MASK_PATH,transform,mask_transforms)\ntest_dataloader = DataLoader(dataset = test_dataset , batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:11:03.048167Z","iopub.execute_input":"2022-05-12T17:11:03.048451Z","iopub.status.idle":"2022-05-12T17:11:09.077237Z","shell.execute_reply.started":"2022-05-12T17:11:03.048419Z","shell.execute_reply":"2022-05-12T17:11:09.076494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ensemble(pred1,pred2,pred3,pred4,pred5,classes):\n    batch = []\n    for b in range(len(pred1)):\n        pred = []\n        for i in range(classes):\n            stack_preds = np.amax(np.stack([pred1[b][i],pred2[b][i],pred3[b][i],pred4[b][i],pred5[b][i]],axis=0),axis=0)\n            pred.append(stack_preds)\n        pred = np.stack(pred,axis=0)\n        batch.append(pred)\n    batch = np.stack(batch,axis=0)\n    return torch.from_numpy(batch)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:11:09.078841Z","iopub.execute_input":"2022-05-12T17:11:09.079085Z","iopub.status.idle":"2022-05-12T17:11:09.086085Z","shell.execute_reply.started":"2022-05-12T17:11:09.079051Z","shell.execute_reply":"2022-05-12T17:11:09.085401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion=nn.CrossEntropyLoss()\ntest_loss = None\nrunning_loss_test = 0\nrunning_iou_score = 0\nrunning_f1_score = 0\nrunning_f2_score = 0\nrunning_accuracy = 0\nrunning_recall = 0\n\nmodel_0.eval()\nmodel_1.eval()\nmodel_2.eval()\nmodel_3.eval()\nmodel_4.eval()\n\nwith torch.no_grad():\n    for x,(inputs,labels) in enumerate(test_dataloader):\n        inputs,labels = inputs.to(device),labels.to(device) \n        output1 = model_0(inputs)[\"out\"].cpu().numpy()\n        output2 = model_1(inputs)[\"out\"].cpu().numpy()\n        output3 = model_2(inputs)[\"out\"].cpu().numpy()\n        output4 = model_3(inputs)[\"out\"].cpu().numpy()\n        output5 = model_4(inputs)[\"out\"].cpu().numpy()\n        \n        prediction = ensemble(output1,output2,output3,output4,output5,32).to(device)\n        prediction = torch.max(prediction,dim=1)\n        \n        tp, fp, fn, tn = smp.metrics.get_stats(prediction[0], labels, mode='multilabel', threshold=0.5)\n        \n        iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n        f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n        f2_score = smp.metrics.fbeta_score(tp, fp, fn, tn, beta=2, reduction=\"micro\")\n        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n        recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n        \n        \n        running_iou_score+=iou_score\n        running_f1_score+=f1_score\n        running_f2_score+=f2_score\n        running_accuracy+=accuracy\n        running_recall+=recall\n        \n\n#         loss_test = criterion(prediction,labels)\n\n#         running_loss_test+=(loss_test.item()*inputs.size(0))\n        \n#     test_loss = running_loss_test/len(test_dataset)\n    \n    print(\"iou score:{iou} f1 score:{f1} f2 score:{f2} acc:{acc} recall:{recall}\".format(iou=running_iou_score/len(test_dataloader),f1=running_f1_score/len(test_dataloader),f2=running_f2_score/len(test_dataloader),acc=running_accuracy/len(test_dataloader),recall=running_recall/len(test_dataloader)))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T17:26:10.397897Z","iopub.execute_input":"2022-05-12T17:26:10.398154Z","iopub.status.idle":"2022-05-12T17:26:55.426674Z","shell.execute_reply.started":"2022-05-12T17:26:10.398121Z","shell.execute_reply":"2022-05-12T17:26:55.425883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}